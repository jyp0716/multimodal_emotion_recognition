{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import menpo\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from moviepy.editor import VideoFileClip\n",
    "from menpo.visualize import progress_bar_str, print_progress\n",
    "from menpo.image import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_dir = Path('/vol/atlas/homes/gt108/db/RECOLA_CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defines the subject ids for each dataset portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "portion_to_id = dict(\n",
    "    train=[15, 16 ,17 ,18 ,21 ,23 ,25 ,37 ,39 ,41 ,46 ,50 ,51 ,55 ,56, 60],\n",
    "    valid=[14, 19, 24, 26, 28, 30, 34, 40, 42, 43, 44, 45, 52, 64, 65],\n",
    "    test=[13, 20, 22, 32, 38, 47, 48, 49, 53, 54, 57, 58, 59, 62, 63]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_face(img, boundary=50, group=None, shape=(256, 256)):\n",
    "    pc = img.landmarks[group].lms\n",
    "    nan_points = np.any(np.isnan(pc.points).reshape(-1, 2), 1)\n",
    "\n",
    "    pc = PointCloud(pc.points[~nan_points, :])\n",
    "    min_indices, max_indices = pc.bounds(boundary=boundary)\n",
    "    h = max_indices[0] - min_indices[0]\n",
    "    w = max_indices[1] - min_indices[1]\n",
    "    pad = abs(w - h)\n",
    "\n",
    "    try:\n",
    "        index = 1 - int(w > h)\n",
    "        min_indices[index] -= int(pad / 2.)\n",
    "        max_indices[index] += int(pad / 2.) + int(pad) % 2\n",
    "\n",
    "        img = img.crop(min_indices, max_indices, constrain_to_boundary=True)\n",
    "    except Exception as e:\n",
    "        print(\"Exception in crop_face\", e)\n",
    "\n",
    "    img = img.resize(shape)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "landmarks_directory = Path('/vol/atlas/homes/grigoris/videos_external/panag/landmarks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_samples(subject_id):\n",
    "    arousal_label_path = root_dir / 'Ratings_affective_behaviour_CCC_centred/arousal/{}.csv'.format(subject_id)\n",
    "    valence_label_path = root_dir / 'Ratings_affective_behaviour_CCC_centred/valence/{}.csv'.format(subject_id)\n",
    "    \n",
    "    clip = VideoFileClip(str(root_dir / \"Video_recordings_MP4/{}.mp4\".format(subject_id)))\n",
    "    \n",
    "    subsampled_audio = clip.audio.set_fps(16000)\n",
    "    video_frames = []\n",
    "    audio_frames = []\n",
    "    \n",
    "    for i in range(1, 7501):\n",
    "        time = 0.04 * i\n",
    "        \n",
    "        video = clip.get_frame(time)\n",
    "        audio = np.array(list(subsampled_audio.subclip(time - 0.04, time).iter_frames())).mean(1)\n",
    "        \n",
    "        video_frames.append(video)\n",
    "        audio_frames.append(audio.astype(np.float32))\n",
    "    \n",
    "    arousal = np.loadtxt(str(arousal_label_path), delimiter=',')[:, 1][1:]\n",
    "    valence = np.loadtxt(str(valence_label_path), delimiter=',')[:, 1][1:]\n",
    "    \n",
    "    return video_frames, audio_frames, np.dstack([arousal, valence])[0].astype(np.float32)\n",
    "\n",
    "def get_jpg_string(im):\n",
    "    # Gets the serialized jpg from a menpo `Image`.\n",
    "    fp = BytesIO()\n",
    "    menpo.io.export_image(im, fp, extension='jpg')\n",
    "    fp.seek(0)\n",
    "    return fp.read()\n",
    "\n",
    "def _int_feauture(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feauture(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def serialize_sample(writer, subject_id):\n",
    "    subject_name = 'P{}'.format(subject_id)\n",
    "    \n",
    "    for i, (video, audio, label) in enumerate(zip(*get_samples(subject_name))):\n",
    "        \n",
    "        frame = Image.init_from_channels_at_back(video)\n",
    "        lms_path = landmarks_directory / subject_name / \"{}.pts\".format(i)\n",
    "        \n",
    "        try:\n",
    "            lms =  mio.import_landmark_file(lms_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        frame.landmarks['PTS'] = lms\n",
    "        frame = crop_face(frame)\n",
    "        \n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                    'sample_id': _int_feauture(i),\n",
    "                    'subject_id': _int_feauture(subject_id),\n",
    "                    'label': _bytes_feauture(label.tobytes()),\n",
    "                    'raw_audio': _bytes_feauture(audio.tobytes()),\n",
    "                    'frame': _bytes_feauture(get_jpg_string(frame))\n",
    "                }))\n",
    "\n",
    "        writer.write(example.SerializeToString())\n",
    "        del video, audio, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "for portion in portion_to_id.keys():\n",
    "    print(portion)\n",
    "    \n",
    "    for subj_id in print_progress(portion_to_id[portion]):\n",
    "        writer = tf.python_io.TFRecordWriter(\n",
    "            (root_dir / 'tf_records' / portion / '{}.tfrecords'.format(subj_id)\n",
    "            ).as_posix())\n",
    "        serialize_sample(writer, subj_id)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:menpo]",
   "language": "python",
   "name": "conda-env-menpo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

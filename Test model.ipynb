{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import data_provider\n",
    "import emotion_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from menpo.visualize import print_progress\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nogpu_config = tf.ConfigProto(\n",
    "    # Do not use a GPU device\n",
    "    device_count = {'GPU': 0}\n",
    ")\n",
    "\n",
    "sess = tf.Session(config=nogpu_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "audio, ground_truth = data_provider.get_split('valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('net'):\n",
    "    with slim.arg_scope([slim.batch_norm, slim.layers.dropout],\n",
    "                        is_training=False):\n",
    "        prediction = emotion_model.audio_model(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt/train/model.ckpt-1195\n"
     ]
    }
   ],
   "source": [
    "variables_to_restore = slim.get_variables_to_restore()\n",
    "saver = tf.train.Saver(variables_to_restore)\n",
    "model_path = slim.evaluation.tf_saver.get_checkpoint_state('ckpt/train').model_checkpoint_path\n",
    "saver.restore(sess, model_path)\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tf.train.start_queue_runners(sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "gts = []\n",
    "\n",
    "for i in print_progress(range(5)):\n",
    "    p, gt = sess.run([prediction, ground_truth])\n",
    "    predictions.append(p)\n",
    "    gts.append(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concordance_cc(r1, r2):\n",
    "    mean_cent_prod = ((r1 - r1.mean()) * (r2 - r2.mean())).mean()\n",
    "\n",
    "    return (2 * mean_cent_prod) / (r1.var() + r2.var() + (r1.mean() - r2.mean()) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(predictions[0][..., 0].ravel())\n",
    "plt.plot(gts[0][..., 0].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "concordance_cc(np.array(predictions)[..., 0].ravel(), np.array(gts)[..., 0].ravel())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
